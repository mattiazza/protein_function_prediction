{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio import Align\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio.Data import IUPACData\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "'''import cafaeval\n",
    "from cafaeval.evaluation import cafa_eval\n",
    "from cafaeval.parser import obo_parser, gt_parser'''\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to train data\n",
    "training_data_path = Path('../data/train')\n",
    "\n",
    "# Path to test data\n",
    "test_data_path = Path('../data/test')\n",
    "\n",
    "# Path to baseline data\n",
    "baseline_data_path = Path('../data/baseline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O43747', 'Q969H0', 'Q9JMA2', 'P18065', 'A0A8I6AN32']\n"
     ]
    }
   ],
   "source": [
    "# Extracting test_ids.txt\n",
    "with open(test_data_path / 'test_ids.txt', 'r') as file:\n",
    "    test_ids = file.read().splitlines()\n",
    "\n",
    "# Display the first few IDs to verify\n",
    "print(test_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: O43747\n",
      "Name: O43747\n",
      "Description: O43747\n",
      "Number of features: 0\n",
      "Seq('MPAPIRLRELIRTIRTARTQAEEREMIQKECAAIRSSFREEDNTYRCRNVAKLL...SWQ')\n"
     ]
    }
   ],
   "source": [
    "test_fasta_list = list(SeqIO.parse(test_data_path / 'test.fasta', 'fasta'))\n",
    "\n",
    "# Print the first sequence to verify\n",
    "print(test_fasta_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>num_features</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O43747</td>\n",
       "      <td>O43747</td>\n",
       "      <td>O43747</td>\n",
       "      <td>0</td>\n",
       "      <td>(M, P, A, P, I, R, L, R, E, L, I, R, T, I, R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q969H0</td>\n",
       "      <td>Q969H0</td>\n",
       "      <td>Q969H0</td>\n",
       "      <td>0</td>\n",
       "      <td>(M, N, Q, E, L, L, S, V, G, S, K, R, R, R, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9JMA2</td>\n",
       "      <td>Q9JMA2</td>\n",
       "      <td>Q9JMA2</td>\n",
       "      <td>0</td>\n",
       "      <td>(M, A, A, V, G, S, P, G, S, L, E, S, A, P, R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P18065</td>\n",
       "      <td>P18065</td>\n",
       "      <td>P18065</td>\n",
       "      <td>0</td>\n",
       "      <td>(M, L, P, R, V, G, C, P, A, L, P, L, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A8I6AN32</td>\n",
       "      <td>A0A8I6AN32</td>\n",
       "      <td>A0A8I6AN32</td>\n",
       "      <td>0</td>\n",
       "      <td>(M, A, S, N, D, Y, T, Q, Q, A, T, Q, S, Y, G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        name description  num_features  \\\n",
       "0      O43747      O43747      O43747             0   \n",
       "1      Q969H0      Q969H0      Q969H0             0   \n",
       "2      Q9JMA2      Q9JMA2      Q9JMA2             0   \n",
       "3      P18065      P18065      P18065             0   \n",
       "4  A0A8I6AN32  A0A8I6AN32  A0A8I6AN32             0   \n",
       "\n",
       "                                            sequence  \n",
       "0  (M, P, A, P, I, R, L, R, E, L, I, R, T, I, R, ...  \n",
       "1  (M, N, Q, E, L, L, S, V, G, S, K, R, R, R, T, ...  \n",
       "2  (M, A, A, V, G, S, P, G, S, L, E, S, A, P, R, ...  \n",
       "3  (M, L, P, R, V, G, C, P, A, L, P, L, P, P, P, ...  \n",
       "4  (M, A, S, N, D, Y, T, Q, Q, A, T, Q, S, Y, G, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant information from SeqRecord\n",
    "test_fasta_dict = [{\n",
    "    'ID': record.id,\n",
    "    'name': record.name,\n",
    "    'description': record.description,\n",
    "    'num_features': len(record.features),\n",
    "    'sequence': record.seq,\n",
    "} for record in test_fasta_list]\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "test_fasta = pd.DataFrame(test_fasta_dict)\n",
    "\n",
    "# Display the DataFrame\n",
    "test_fasta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 0 differences between the ID and name columns.\n",
      "We have a total of 0 differences between the ID and description columns.\n"
     ]
    }
   ],
   "source": [
    "# Checking for differences between the ID and name columns\n",
    "diff_id_name = sum(test_fasta['ID'] != test_fasta['name'])\n",
    "\n",
    "# Checking for differences between the ID and description columns\n",
    "diff_id_description = sum(test_fasta['ID'] != test_fasta['description'])\n",
    "\n",
    "print(f\"We have a total of {diff_id_name} differences between the ID and name columns.\\nWe have a total of {diff_id_description} differences between the ID and description columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 0 sequences with features.\n"
     ]
    }
   ],
   "source": [
    "num_features_values = sum(test_fasta['num_features'] != 0)\n",
    "\n",
    "print(f\"We have a total of {num_features_values} sequences with features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O43747</td>\n",
       "      <td>(M, P, A, P, I, R, L, R, E, L, I, R, T, I, R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q969H0</td>\n",
       "      <td>(M, N, Q, E, L, L, S, V, G, S, K, R, R, R, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9JMA2</td>\n",
       "      <td>(M, A, A, V, G, S, P, G, S, L, E, S, A, P, R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P18065</td>\n",
       "      <td>(M, L, P, R, V, G, C, P, A, L, P, L, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A8I6AN32</td>\n",
       "      <td>(M, A, S, N, D, Y, T, Q, Q, A, T, Q, S, Y, G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                           sequence\n",
       "0      O43747  (M, P, A, P, I, R, L, R, E, L, I, R, T, I, R, ...\n",
       "1      Q969H0  (M, N, Q, E, L, L, S, V, G, S, K, R, R, R, T, ...\n",
       "2      Q9JMA2  (M, A, A, V, G, S, P, G, S, L, E, S, A, P, R, ...\n",
       "3      P18065  (M, L, P, R, V, G, C, P, A, L, P, L, P, P, P, ...\n",
       "4  A0A8I6AN32  (M, A, S, N, D, Y, T, Q, Q, A, T, Q, S, Y, G, ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fasta.drop(columns=['name', 'description', 'num_features'], inplace=True)\n",
    "\n",
    "\n",
    "test_fasta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of IDs in train_ids.txt is equal to the number of unique IDs in the train set (1000).\n",
      "Proceeding with the analysis.\n"
     ]
    }
   ],
   "source": [
    "len_ID = len(test_fasta['ID'].unique()) # assigned because gave problem on else statement print\n",
    "\n",
    "if len(test_ids) == len_ID:\n",
    "    print(f\"The number of IDs in train_ids.txt is equal to the number of unique IDs in the train set ({len(test_ids)}).\\n\"\n",
    "          \"Proceeding with the analysis.\")\n",
    "else:\n",
    "    print(f'The numbers are not the same: test_ids are {len(test_ids)}, while the length of the fasta file is {len_ID})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0B4JCV4</td>\n",
       "      <td>[0.00979, -0.03973, 0.03653, -0.006447, -0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>[0.02786, -0.01154, 0.008865, -0.01765, 0.0073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0B4P506</td>\n",
       "      <td>[0.01643, 0.01802, 0.03702, -0.0591, 0.0356, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0G2K1A2</td>\n",
       "      <td>[0.00882, 0.0835, -0.001374, -0.0003645, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0G2K1V4</td>\n",
       "      <td>[0.0659, 0.0929, -0.001803, 0.0226, 0.0383, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                         embeddings\n",
       "0  A0A0B4JCV4  [0.00979, -0.03973, 0.03653, -0.006447, -0.040...\n",
       "1  A0A0B4KHT0  [0.02786, -0.01154, 0.008865, -0.01765, 0.0073...\n",
       "2  A0A0B4P506  [0.01643, 0.01802, 0.03702, -0.0591, 0.0356, 0...\n",
       "3  A0A0G2K1A2  [0.00882, 0.0835, -0.001374, -0.0003645, -0.06...\n",
       "4  A0A0G2K1V4  [0.0659, 0.0929, -0.001803, 0.0226, 0.0383, 0...."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "with h5py.File(test_data_path / \"test_embeddings.h5\", \"r\") as f:\n",
    "    for dataset_name in f.keys():\n",
    "        dataset = f[dataset_name][:]\n",
    "        data_list.append([dataset_name, dataset])\n",
    "\n",
    "test_embeddings = pd.DataFrame(data_list, columns=[\"ID\", \"embeddings\"])\n",
    "\n",
    "test_embeddings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ipr</th>\n",
       "      <th>domain</th>\n",
       "      <th>familyID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0B4JCV4</td>\n",
       "      <td>IPR039915</td>\n",
       "      <td>TACC family</td>\n",
       "      <td>PTHR13924</td>\n",
       "      <td>38</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>IPR000315</td>\n",
       "      <td>B-box-type zinc finger</td>\n",
       "      <td>PF00643</td>\n",
       "      <td>177</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>IPR000315</td>\n",
       "      <td>B-box-type zinc finger</td>\n",
       "      <td>PF00643</td>\n",
       "      <td>236</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>IPR000315</td>\n",
       "      <td>B-box-type zinc finger</td>\n",
       "      <td>PS50119</td>\n",
       "      <td>173</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>IPR000315</td>\n",
       "      <td>B-box-type zinc finger</td>\n",
       "      <td>PS50119</td>\n",
       "      <td>235</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        ipr                  domain   familyID  start   end\n",
       "0  A0A0B4JCV4  IPR039915             TACC family  PTHR13924     38  1206\n",
       "1  A0A0B4KHT0  IPR000315  B-box-type zinc finger    PF00643    177   219\n",
       "2  A0A0B4KHT0  IPR000315  B-box-type zinc finger    PF00643    236   274\n",
       "3  A0A0B4KHT0  IPR000315  B-box-type zinc finger    PS50119    173   220\n",
       "4  A0A0B4KHT0  IPR000315  B-box-type zinc finger    PS50119    235   282"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_protein2ipr = pd.read_csv(test_data_path / 'test_protein2ipr.dat', sep='\\t')\n",
    "\n",
    "# Rename Protein_ID and aspect columns\n",
    "test_protein2ipr.columns = ['ID', 'ipr', 'domain', 'familyID', 'start', 'end']\n",
    "\n",
    "# Remove 'domain' that is useless\n",
    "test_protein2ipr.drop('domain', axis=1)\n",
    "\n",
    "test_protein2ipr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test protein2ipr ((11263, 6)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ipr</th>\n",
       "      <th>domain</th>\n",
       "      <th>familyID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0B4JCV4</td>\n",
       "      <td>(IPR039915,)</td>\n",
       "      <td>(TACC family,)</td>\n",
       "      <td>(PTHR13924,)</td>\n",
       "      <td>(38,)</td>\n",
       "      <td>(1206,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>(IPR000315, IPR000315, IPR000315, IPR000315, I...</td>\n",
       "      <td>(B-box-type zinc finger, B-box-type zinc finge...</td>\n",
       "      <td>(PF00643, PF00643, PS50119, PS50119, SM00336, ...</td>\n",
       "      <td>(177, 236, 173, 235, 173, 235, 976, 826, 988, ...</td>\n",
       "      <td>(219, 274, 220, 282, 220, 276, 1048, 839, 1004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0B4P506</td>\n",
       "      <td>(IPR003417, IPR003417, IPR036552, IPR036552)</td>\n",
       "      <td>(Core-binding factor, beta subunit, Core-bindi...</td>\n",
       "      <td>(PF02312, PTHR10276, G3DSA:2.40.250.10, SSF50723)</td>\n",
       "      <td>(1, 1, 1, 4)</td>\n",
       "      <td>(164, 168, 142, 140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0G2K1A2</td>\n",
       "      <td>(IPR010255, IPR019791, IPR019791, IPR019791, I...</td>\n",
       "      <td>(Haem peroxidase superfamily, Haem peroxidase,...</td>\n",
       "      <td>(SSF48113, PF03098, PR00457, PR00457, PR00457,...</td>\n",
       "      <td>(142, 148, 172, 226, 374, 392, 417, 470, 598, ...</td>\n",
       "      <td>(718, 692, 183, 241, 392, 412, 443, 480, 618, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0G2K1V4</td>\n",
       "      <td>(IPR000048, IPR000048, IPR001609, IPR001609, I...</td>\n",
       "      <td>(IQ motif, EF-hand binding site, IQ motif, EF-...</td>\n",
       "      <td>(PS50096, SM00015, PF00063, PR00193, PR00193, ...</td>\n",
       "      <td>(789, 788, 89, 116, 172, 228, 459, 513, 86, 80...</td>\n",
       "      <td>(818, 810, 774, 135, 197, 255, 487, 541, 786, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                                ipr  \\\n",
       "0  A0A0B4JCV4                                       (IPR039915,)   \n",
       "1  A0A0B4KHT0  (IPR000315, IPR000315, IPR000315, IPR000315, I...   \n",
       "2  A0A0B4P506       (IPR003417, IPR003417, IPR036552, IPR036552)   \n",
       "3  A0A0G2K1A2  (IPR010255, IPR019791, IPR019791, IPR019791, I...   \n",
       "4  A0A0G2K1V4  (IPR000048, IPR000048, IPR001609, IPR001609, I...   \n",
       "\n",
       "                                              domain  \\\n",
       "0                                     (TACC family,)   \n",
       "1  (B-box-type zinc finger, B-box-type zinc finge...   \n",
       "2  (Core-binding factor, beta subunit, Core-bindi...   \n",
       "3  (Haem peroxidase superfamily, Haem peroxidase,...   \n",
       "4  (IQ motif, EF-hand binding site, IQ motif, EF-...   \n",
       "\n",
       "                                            familyID  \\\n",
       "0                                       (PTHR13924,)   \n",
       "1  (PF00643, PF00643, PS50119, PS50119, SM00336, ...   \n",
       "2  (PF02312, PTHR10276, G3DSA:2.40.250.10, SSF50723)   \n",
       "3  (SSF48113, PF03098, PR00457, PR00457, PR00457,...   \n",
       "4  (PS50096, SM00015, PF00063, PR00193, PR00193, ...   \n",
       "\n",
       "                                               start  \\\n",
       "0                                              (38,)   \n",
       "1  (177, 236, 173, 235, 173, 235, 976, 826, 988, ...   \n",
       "2                                       (1, 1, 1, 4)   \n",
       "3  (142, 148, 172, 226, 374, 392, 417, 470, 598, ...   \n",
       "4  (789, 788, 89, 116, 172, 228, 459, 513, 86, 80...   \n",
       "\n",
       "                                                 end  \n",
       "0                                            (1206,)  \n",
       "1  (219, 274, 220, 282, 220, 276, 1048, 839, 1004...  \n",
       "2                               (164, 168, 142, 140)  \n",
       "3  (718, 692, 183, 241, 392, 412, 443, 480, 618, ...  \n",
       "4  (818, 810, 774, 135, 197, 255, 487, 541, 786, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'ID' and aggregate other columns into lists\n",
    "test_protein2ipr_grouped = test_protein2ipr.groupby('ID').agg(lambda x: tuple(x)).reset_index()\n",
    "\n",
    "print(f\"Test protein2ipr ({test_protein2ipr.shape}):\")\n",
    "test_protein2ipr_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows missing from train_protein2ipr_grouped: 19\n",
      "Combined DataFrame shape: (1000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ipr</th>\n",
       "      <th>domain</th>\n",
       "      <th>familyID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0B4JCV4</td>\n",
       "      <td>[0.00979, -0.03973, 0.03653, -0.006447, -0.040...</td>\n",
       "      <td>(M, E, F, D, D, A, E, N, G, L, G, M, G, F, G, ...</td>\n",
       "      <td>(IPR039915,)</td>\n",
       "      <td>(TACC family,)</td>\n",
       "      <td>(PTHR13924,)</td>\n",
       "      <td>(38,)</td>\n",
       "      <td>(1206,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0B4KHT0</td>\n",
       "      <td>[0.02786, -0.01154, 0.008865, -0.01765, 0.0073...</td>\n",
       "      <td>(M, D, M, D, L, E, Q, L, K, N, D, F, L, P, L, ...</td>\n",
       "      <td>(IPR000315, IPR000315, IPR000315, IPR000315, I...</td>\n",
       "      <td>(B-box-type zinc finger, B-box-type zinc finge...</td>\n",
       "      <td>(PF00643, PF00643, PS50119, PS50119, SM00336, ...</td>\n",
       "      <td>(177, 236, 173, 235, 173, 235, 976, 826, 988, ...</td>\n",
       "      <td>(219, 274, 220, 282, 220, 276, 1048, 839, 1004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0B4P506</td>\n",
       "      <td>[0.01643, 0.01802, 0.03702, -0.0591, 0.0356, 0...</td>\n",
       "      <td>(M, P, R, V, V, P, D, Q, R, S, K, F, E, N, E, ...</td>\n",
       "      <td>(IPR003417, IPR003417, IPR036552, IPR036552)</td>\n",
       "      <td>(Core-binding factor, beta subunit, Core-bindi...</td>\n",
       "      <td>(PF02312, PTHR10276, G3DSA:2.40.250.10, SSF50723)</td>\n",
       "      <td>(1, 1, 1, 4)</td>\n",
       "      <td>(164, 168, 142, 140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0G2K1A2</td>\n",
       "      <td>[0.00882, 0.0835, -0.001374, -0.0003645, -0.06...</td>\n",
       "      <td>(M, K, L, F, L, A, L, A, G, L, L, A, P, L, A, ...</td>\n",
       "      <td>(IPR010255, IPR019791, IPR019791, IPR019791, I...</td>\n",
       "      <td>(Haem peroxidase superfamily, Haem peroxidase,...</td>\n",
       "      <td>(SSF48113, PF03098, PR00457, PR00457, PR00457,...</td>\n",
       "      <td>(142, 148, 172, 226, 374, 392, 417, 470, 598, ...</td>\n",
       "      <td>(718, 692, 183, 241, 392, 412, 443, 480, 618, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0G2K1V4</td>\n",
       "      <td>[0.0659, 0.0929, -0.001803, 0.0226, 0.0383, 0....</td>\n",
       "      <td>(M, S, S, D, A, E, M, A, V, F, G, E, A, A, P, ...</td>\n",
       "      <td>(IPR000048, IPR000048, IPR001609, IPR001609, I...</td>\n",
       "      <td>(IQ motif, EF-hand binding site, IQ motif, EF-...</td>\n",
       "      <td>(PS50096, SM00015, PF00063, PR00193, PR00193, ...</td>\n",
       "      <td>(789, 788, 89, 116, 172, 228, 459, 513, 86, 80...</td>\n",
       "      <td>(818, 810, 774, 135, 197, 255, 487, 541, 786, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                         embeddings  \\\n",
       "0  A0A0B4JCV4  [0.00979, -0.03973, 0.03653, -0.006447, -0.040...   \n",
       "1  A0A0B4KHT0  [0.02786, -0.01154, 0.008865, -0.01765, 0.0073...   \n",
       "2  A0A0B4P506  [0.01643, 0.01802, 0.03702, -0.0591, 0.0356, 0...   \n",
       "3  A0A0G2K1A2  [0.00882, 0.0835, -0.001374, -0.0003645, -0.06...   \n",
       "4  A0A0G2K1V4  [0.0659, 0.0929, -0.001803, 0.0226, 0.0383, 0....   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  (M, E, F, D, D, A, E, N, G, L, G, M, G, F, G, ...   \n",
       "1  (M, D, M, D, L, E, Q, L, K, N, D, F, L, P, L, ...   \n",
       "2  (M, P, R, V, V, P, D, Q, R, S, K, F, E, N, E, ...   \n",
       "3  (M, K, L, F, L, A, L, A, G, L, L, A, P, L, A, ...   \n",
       "4  (M, S, S, D, A, E, M, A, V, F, G, E, A, A, P, ...   \n",
       "\n",
       "                                                 ipr  \\\n",
       "0                                       (IPR039915,)   \n",
       "1  (IPR000315, IPR000315, IPR000315, IPR000315, I...   \n",
       "2       (IPR003417, IPR003417, IPR036552, IPR036552)   \n",
       "3  (IPR010255, IPR019791, IPR019791, IPR019791, I...   \n",
       "4  (IPR000048, IPR000048, IPR001609, IPR001609, I...   \n",
       "\n",
       "                                              domain  \\\n",
       "0                                     (TACC family,)   \n",
       "1  (B-box-type zinc finger, B-box-type zinc finge...   \n",
       "2  (Core-binding factor, beta subunit, Core-bindi...   \n",
       "3  (Haem peroxidase superfamily, Haem peroxidase,...   \n",
       "4  (IQ motif, EF-hand binding site, IQ motif, EF-...   \n",
       "\n",
       "                                            familyID  \\\n",
       "0                                       (PTHR13924,)   \n",
       "1  (PF00643, PF00643, PS50119, PS50119, SM00336, ...   \n",
       "2  (PF02312, PTHR10276, G3DSA:2.40.250.10, SSF50723)   \n",
       "3  (SSF48113, PF03098, PR00457, PR00457, PR00457,...   \n",
       "4  (PS50096, SM00015, PF00063, PR00193, PR00193, ...   \n",
       "\n",
       "                                               start  \\\n",
       "0                                              (38,)   \n",
       "1  (177, 236, 173, 235, 173, 235, 976, 826, 988, ...   \n",
       "2                                       (1, 1, 1, 4)   \n",
       "3  (142, 148, 172, 226, 374, 392, 417, 470, 598, ...   \n",
       "4  (789, 788, 89, 116, 172, 228, 459, 513, 86, 80...   \n",
       "\n",
       "                                                 end  \n",
       "0                                            (1206,)  \n",
       "1  (219, 274, 220, 282, 220, 276, 1048, 839, 1004...  \n",
       "2                               (164, 168, 142, 140)  \n",
       "3  (718, 692, 183, 241, 392, 412, 443, 480, 618, ...  \n",
       "4  (818, 810, 774, 135, 197, 255, 487, 541, 786, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test = pd.merge(test_embeddings, test_fasta, on='ID')\n",
    "combined_test = pd.merge(combined_test, test_protein2ipr_grouped, on='ID', how='left')\n",
    "\n",
    "missing_rows = combined_test[combined_test['ipr'].isna()].shape[0]\n",
    "print(f\"Number of rows missing from train_protein2ipr_grouped: {missing_rows}\")\n",
    "\n",
    "print(f\"Combined DataFrame shape: {combined_test.shape}\")\n",
    "combined_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = combined_test[['ID','embeddings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([1000, 1024])\n",
      "First few IDs: ['A0A0B4JCV4', 'A0A0B4KHT0', 'A0A0B4P506', 'A0A0G2K1A2', 'A0A0G2K1V4']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Expand vectors while keeping IDs as index\n",
    "df_expanded = X_test.set_index('ID')['embeddings'].apply(lambda x: x.flatten()).apply(pd.Series)\n",
    "\n",
    "# Step 2: Convert expanded DataFrame to a PyTorch tensor\n",
    "tensor = torch.tensor(df_expanded.values, dtype=torch.float32)\n",
    "\n",
    "# Step 3: Keep IDs as a list for reference\n",
    "protein_ids = df_expanded.index.tolist()\n",
    "\n",
    "# Verifying the outputs\n",
    "print(\"Tensor shape:\", tensor.shape)  # Expected: torch.Size([1000, 1024])\n",
    "print(\"First few IDs:\", protein_ids[:5])  # Checking the first few IDs\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_test_tensor = tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein_ids = combined_test[\"ID\"].tolist()\n",
    "# protein_ids = np.array(protein_ids)  # Keep it as an array to ensure alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to tensor\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# # Move to GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# X_test_tensor = X_test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\n\\ndef format_predictions(protein_ids, go_terms, y_pred, threshold=0.2, max_labels_per_protein=1500, min_threshold=0.05):\\n    \"\"\"\\n    Formats the model predictions according to the competition rules.\\n\\n    Args:\\n    - protein_ids (list): List of protein target IDs.\\n    - go_terms (list): List of GO term labels corresponding to output nodes.\\n    - y_pred (numpy.ndarray): Predicted probabilities (shape: [num_proteins, num_classes]).\\n    - threshold (float): Minimum probability to include a GO term.\\n    - max_labels_per_protein (int): Maximum allowed labels per protein.\\n    - min_threshold (float): Lower probability bound if additional labels are needed.\\n\\n    Returns:\\n    - list of formatted predictions (protein_id, go_term, probability)\\n    \"\"\"\\n    formatted_results = []\\n\\n    for i, protein_id in enumerate(protein_ids):\\n        # Get predictions and sort them in descending order\\n        pred_probs = y_pred[i]\\n        sorted_indices = np.argsort(-pred_probs)  # Descending order\\n\\n        # Select labels above threshold\\n        selected_indices = [idx for idx in sorted_indices if pred_probs[idx] > threshold]\\n\\n        # If too many labels, keep only top-K\\n        if len(selected_indices) > max_labels_per_protein:\\n            selected_indices = selected_indices[:max_labels_per_protein]\\n\\n        # If too few labels, add lower-probability terms down to min_threshold\\n        elif len(selected_indices) < max_labels_per_protein:\\n            additional_indices = [idx for idx in sorted_indices if min_threshold <= pred_probs[idx] <= threshold]\\n            additional_needed = max_labels_per_protein - len(selected_indices)\\n            selected_indices += additional_indices[:additional_needed]\\n\\n        # Format predictions\\n        for idx in selected_indices:\\n            go_term = go_terms[idx]\\n            probability = round(float(pred_probs[idx]), 3)  # Keep 3 decimal places\\n            probability = max(probability, 0.001)  # Ensure probability > 0\\n            formatted_results.append(f\"{protein_id} {go_term} {probability}\")\\n\\n    return formatted_results\\n\\n# Example usage:\\n# protein_ids = [\\'P9WHI7\\', \\'P04637\\', ...]  # List of protein IDs\\n# go_terms = [\\'GO:0009274\\', \\'GO:0071944\\', \\'GO:0005575\\', ...]  # GO terms corresponding to model outputs\\n# y_pred = model1_cc(X_test_tensor).cpu().numpy()  # Get model predictions\\n# result_lines = format_predictions(protein_ids, go_terms, y_pred, threshold=0.2, max_labels_per_protein=1500, min_threshold=0.05)\\n\\n# Print or save results\\n# for line in result_lines:\\n#     print(line)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "\n",
    "def format_predictions(protein_ids, go_terms, y_pred, threshold=0.2, max_labels_per_protein=1500, min_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Formats the model predictions according to the competition rules.\n",
    "\n",
    "    Args:\n",
    "    - protein_ids (list): List of protein target IDs.\n",
    "    - go_terms (list): List of GO term labels corresponding to output nodes.\n",
    "    - y_pred (numpy.ndarray): Predicted probabilities (shape: [num_proteins, num_classes]).\n",
    "    - threshold (float): Minimum probability to include a GO term.\n",
    "    - max_labels_per_protein (int): Maximum allowed labels per protein.\n",
    "    - min_threshold (float): Lower probability bound if additional labels are needed.\n",
    "\n",
    "    Returns:\n",
    "    - list of formatted predictions (protein_id, go_term, probability)\n",
    "    \"\"\"\n",
    "    formatted_results = []\n",
    "\n",
    "    for i, protein_id in enumerate(protein_ids):\n",
    "        # Get predictions and sort them in descending order\n",
    "        pred_probs = y_pred[i]\n",
    "        sorted_indices = np.argsort(-pred_probs)  # Descending order\n",
    "\n",
    "        # Select labels above threshold\n",
    "        selected_indices = [idx for idx in sorted_indices if pred_probs[idx] > threshold]\n",
    "\n",
    "        # If too many labels, keep only top-K\n",
    "        if len(selected_indices) > max_labels_per_protein:\n",
    "            selected_indices = selected_indices[:max_labels_per_protein]\n",
    "\n",
    "        # If too few labels, add lower-probability terms down to min_threshold\n",
    "        elif len(selected_indices) < max_labels_per_protein:\n",
    "            additional_indices = [idx for idx in sorted_indices if min_threshold <= pred_probs[idx] <= threshold]\n",
    "            additional_needed = max_labels_per_protein - len(selected_indices)\n",
    "            selected_indices += additional_indices[:additional_needed]\n",
    "\n",
    "        # Format predictions\n",
    "        for idx in selected_indices:\n",
    "            go_term = go_terms[idx]\n",
    "            probability = round(float(pred_probs[idx]), 3)  # Keep 3 decimal places\n",
    "            probability = max(probability, 0.001)  # Ensure probability > 0\n",
    "            formatted_results.append(f\"{protein_id} {go_term} {probability}\")\n",
    "\n",
    "    return formatted_results\n",
    "\n",
    "# Example usage:\n",
    "# protein_ids = ['P9WHI7', 'P04637', ...]  # List of protein IDs\n",
    "# go_terms = ['GO:0009274', 'GO:0071944', 'GO:0005575', ...]  # GO terms corresponding to model outputs\n",
    "# y_pred = model1_cc(X_test_tensor).cpu().numpy()  # Get model predictions\n",
    "# result_lines = format_predictions(protein_ids, go_terms, y_pred, threshold=0.2, max_labels_per_protein=1500, min_threshold=0.05)\n",
    "\n",
    "# Print or save results\n",
    "# for line in result_lines:\n",
    "#     print(line)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport pickle\\nimport numpy as np\\n\\n# Load saved models\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\nmodel_cc = torch.load(\"model_cc.pth\", map_location=device)\\nmodel_bp = torch.load(\"model_bp.pth\", map_location=device)\\nmodel_mf = torch.load(\"model_mf.pth\", map_location=device)\\n\\nmodel_cc.eval()\\nmodel_bp.eval()\\nmodel_mf.eval()\\n\\n# Load MultiLabelBinarizers (MLBs) for mapping indices to GO terms\\nwith open(\"mlb_cc.pkl\", \"rb\") as f:\\n    mlb_cc = pickle.load(f)\\nwith open(\"mlb_bp.pkl\", \"rb\") as f:\\n    mlb_bp = pickle.load(f)\\nwith open(\"mlb_mf.pkl\", \"rb\") as f:\\n    mlb_mf = pickle.load(f)\\n\\n# Function to make predictions with threshold and top-k\\ndef predict_with_threshold(model, X_test, mlb, threshold=0.5, top_k=100):\\n    \"\"\" Generate GO term predictions from a model with a threshold and top-k filtering. \"\"\"\\n    X_test = X_test.to(device)\\n    \\n    with torch.no_grad():\\n        probs = model(X_test).cpu().numpy()  # Get probabilities\\n\\n    predictions = []\\n    for i, prob in enumerate(probs):\\n        # Select indices where probability > threshold\\n        high_confidence_indices = np.where(prob > threshold)[0]\\n        \\n        # Sort indices by probability in descending order\\n        sorted_indices = high_confidence_indices[np.argsort(prob[high_confidence_indices])[::-1]]\\n        \\n        # Keep only the top_k predictions\\n        top_indices = sorted_indices[:top_k]\\n        \\n        # Map indices to GO terms\\n        go_terms = mlb.classes_[top_indices]\\n        \\n        # Store predictions\\n        predictions.append(list(go_terms))\\n    \\n    return predictions, probs  # Return both terms and probabilities\\n\\n# Ensure X_test_tensor is on the same device as the models\\nX_test_tensor = X_test_tensor.to(device)\\n\\n# Get predictions from each model\\npredictions_cc, probs_cc = predict_with_threshold(model_cc, X_test_tensor, mlb_cc, threshold=0.5, top_k=500)\\npredictions_bp, probs_bp = predict_with_threshold(model_bp, X_test_tensor, mlb_bp, threshold=0.5, top_k=500)\\npredictions_mf, probs_mf = predict_with_threshold(model_mf, X_test_tensor, mlb_mf, threshold=0.5, top_k=500)\\n\\n# Merge predictions into a dictionary\\nfinal_predictions = {}\\nfor i, protein_id in enumerate(protein_ids):  # Ensure protein_ids matches test set order\\n    all_terms = set(predictions_cc[i] + predictions_bp[i] + predictions_mf[i])  # Merge GO terms\\n    all_probs = {term: max(probs_cc[i][mlb_cc.transform([[term]])[0][0]] if term in predictions_cc[i] else 0,\\n                           probs_bp[i][mlb_bp.transform([[term]])[0][0]] if term in predictions_bp[i] else 0,\\n                           probs_mf[i][mlb_mf.transform([[term]])[0][0]] if term in predictions_mf[i] else 0)\\n                 for term in all_terms}\\n    \\n    # Sort by highest probabilities and keep top 1500 GO terms per protein\\n    sorted_terms = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)[:1500]\\n    \\n    final_predictions[protein_id] = sorted_terms\\n\\n# Save the predictions in submission format\\nwith open(\"submission.txt\", \"w\") as f:\\n    for protein, terms in final_predictions.items():\\n        for term, score in terms:\\n            formatted_score = round(score, 3)\\n            formatted_score = max(formatted_score, 0.001)  # Ensure score > 0\\n            f.write(f\"{protein} {term} {formatted_score}\\n\")\\n\\nprint(\"Submission file saved as submission.txt\")\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load saved models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_cc = torch.load(\"model_cc.pth\", map_location=device)\n",
    "model_bp = torch.load(\"model_bp.pth\", map_location=device)\n",
    "model_mf = torch.load(\"model_mf.pth\", map_location=device)\n",
    "\n",
    "model_cc.eval()\n",
    "model_bp.eval()\n",
    "model_mf.eval()\n",
    "\n",
    "# Load MultiLabelBinarizers (MLBs) for mapping indices to GO terms\n",
    "with open(\"mlb_cc.pkl\", \"rb\") as f:\n",
    "    mlb_cc = pickle.load(f)\n",
    "with open(\"mlb_bp.pkl\", \"rb\") as f:\n",
    "    mlb_bp = pickle.load(f)\n",
    "with open(\"mlb_mf.pkl\", \"rb\") as f:\n",
    "    mlb_mf = pickle.load(f)\n",
    "\n",
    "# Function to make predictions with threshold and top-k\n",
    "def predict_with_threshold(model, X_test, mlb, threshold=0.5, top_k=100):\n",
    "    \"\"\" Generate GO term predictions from a model with a threshold and top-k filtering. \"\"\"\n",
    "    X_test = X_test.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probs = model(X_test).cpu().numpy()  # Get probabilities\n",
    "\n",
    "    predictions = []\n",
    "    for i, prob in enumerate(probs):\n",
    "        # Select indices where probability > threshold\n",
    "        high_confidence_indices = np.where(prob > threshold)[0]\n",
    "        \n",
    "        # Sort indices by probability in descending order\n",
    "        sorted_indices = high_confidence_indices[np.argsort(prob[high_confidence_indices])[::-1]]\n",
    "        \n",
    "        # Keep only the top_k predictions\n",
    "        top_indices = sorted_indices[:top_k]\n",
    "        \n",
    "        # Map indices to GO terms\n",
    "        go_terms = mlb.classes_[top_indices]\n",
    "        \n",
    "        # Store predictions\n",
    "        predictions.append(list(go_terms))\n",
    "    \n",
    "    return predictions, probs  # Return both terms and probabilities\n",
    "\n",
    "# Ensure X_test_tensor is on the same device as the models\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "\n",
    "# Get predictions from each model\n",
    "predictions_cc, probs_cc = predict_with_threshold(model_cc, X_test_tensor, mlb_cc, threshold=0.5, top_k=500)\n",
    "predictions_bp, probs_bp = predict_with_threshold(model_bp, X_test_tensor, mlb_bp, threshold=0.5, top_k=500)\n",
    "predictions_mf, probs_mf = predict_with_threshold(model_mf, X_test_tensor, mlb_mf, threshold=0.5, top_k=500)\n",
    "\n",
    "# Merge predictions into a dictionary\n",
    "final_predictions = {}\n",
    "for i, protein_id in enumerate(protein_ids):  # Ensure protein_ids matches test set order\n",
    "    all_terms = set(predictions_cc[i] + predictions_bp[i] + predictions_mf[i])  # Merge GO terms\n",
    "    all_probs = {term: max(probs_cc[i][mlb_cc.transform([[term]])[0][0]] if term in predictions_cc[i] else 0,\n",
    "                           probs_bp[i][mlb_bp.transform([[term]])[0][0]] if term in predictions_bp[i] else 0,\n",
    "                           probs_mf[i][mlb_mf.transform([[term]])[0][0]] if term in predictions_mf[i] else 0)\n",
    "                 for term in all_terms}\n",
    "    \n",
    "    # Sort by highest probabilities and keep top 1500 GO terms per protein\n",
    "    sorted_terms = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)[:1500]\n",
    "    \n",
    "    final_predictions[protein_id] = sorted_terms\n",
    "\n",
    "# Save the predictions in submission format\n",
    "with open(\"submission.txt\", \"w\") as f:\n",
    "    for protein, terms in final_predictions.items():\n",
    "        for term, score in terms:\n",
    "            formatted_score = round(score, 3)\n",
    "            formatted_score = max(formatted_score, 0.001)  # Ensure score > 0\n",
    "            f.write(f\"{protein} {term} {formatted_score}\\n\")\n",
    "\n",
    "print(\"Submission file saved as submission.txt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and ready for inference!\n"
     ]
    }
   ],
   "source": [
    "#model for cc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultilabelNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MultilabelNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hidden_sizes[1], output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define device first!\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model parameters\n",
    "input_size = 1024\n",
    "hidden_sizes = [4096, 4096]    \n",
    "output_size = 678   \n",
    "\n",
    "# Initialize the model\n",
    "model_cc = MultilabelNN(input_size, hidden_sizes, output_size).to(device)\n",
    "\n",
    "# Load saved weights\n",
    "model_cc.load_state_dict(torch.load(\"model_cc.pth\", map_location=device))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model_cc.eval()\n",
    "\n",
    "print(\"Model loaded successfully and ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and ready for inference!\n"
     ]
    }
   ],
   "source": [
    "#model for mf\n",
    "\n",
    "class MultilabelNN_mf(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MultilabelNN_mf, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),  # Dropout for regularization\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_sizes[1], output_size),\n",
    "            nn.Sigmoid()  # For multilabel classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define model parameters\n",
    "input_size = 1024  # 300 features\n",
    "hidden_sizes = [4096, 4096]            # Hidden layer sizes\n",
    "output_size = 839    # Number of labels\n",
    "\n",
    "# Initialize the model\n",
    "model_mf = MultilabelNN_mf(input_size, hidden_sizes, output_size).to(device)\n",
    "\n",
    "# Load saved weights\n",
    "model_mf.load_state_dict(torch.load(\"model_mf.pth\", map_location=device))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model_mf.eval()\n",
    "\n",
    "print(\"Model loaded successfully and ready for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and ready for inference!\n"
     ]
    }
   ],
   "source": [
    "#model for bp\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hidden_sizes[1], output_size),\n",
    "            nn.Sigmoid()  # For multilabel classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    # Define model parameters\n",
    "input_size = 1024  # 300 features\n",
    "hidden_sizes = [8192, 4096]            # Hidden layer sizes\n",
    "output_size = 1487    # Number of labels\n",
    "\n",
    "# Initialize the model\n",
    "model_bp = NN(input_size, hidden_sizes, output_size).to(device)\n",
    "\n",
    "# Load saved weights\n",
    "model_bp.load_state_dict(torch.load(\"model_bp.pth\", map_location=device))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model_bp.eval()\n",
    "\n",
    "print(\"Model loaded successfully and ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.txt\n",
      "Submission file saved as submission.tsv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load MultiLabelBinarizers (MLBs) for mapping indices to GO terms\n",
    "with open(\"mlb_cc.pkl\", \"rb\") as f:\n",
    "    mlb_cc = pickle.load(f)\n",
    "with open(\"mlb_bp.pkl\", \"rb\") as f:\n",
    "    mlb_bp = pickle.load(f)\n",
    "with open(\"mlb_mf.pkl\", \"rb\") as f:\n",
    "    mlb_mf = pickle.load(f)\n",
    "\n",
    "# Precompute GO term index mappings (to avoid repeated calls to transform)\n",
    "cc_go_mapping = {idx: term for idx, term in enumerate(mlb_cc.classes_)}\n",
    "bp_go_mapping = {idx: term for idx, term in enumerate(mlb_bp.classes_)}\n",
    "mf_go_mapping = {idx: term for idx, term in enumerate(mlb_mf.classes_)}\n",
    "\n",
    "# Function to make predictions with threshold and top-k filtering\n",
    "def predict_with_threshold(model, X_test, go_mapping, threshold=0.5, top_k=10):\n",
    "    \"\"\" Generate GO term predictions from a model with a threshold and top-k filtering. \"\"\"\n",
    "    X_test = X_test.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = model(X_test).cpu().numpy()  # Get probabilities\n",
    "\n",
    "    predictions = []\n",
    "    for prob in probs:\n",
    "        # Select indices where probability > threshold\n",
    "        high_confidence_indices = np.where(prob > threshold)[0]\n",
    "\n",
    "        # Sort indices by probability in descending order\n",
    "        sorted_indices = high_confidence_indices[np.argsort(prob[high_confidence_indices])[::-1]]\n",
    "\n",
    "        # Keep only the top_k predictions\n",
    "        top_indices = sorted_indices[:top_k]\n",
    "\n",
    "        # Map indices to GO terms\n",
    "        go_terms = [go_mapping[idx] for idx in top_indices]\n",
    "\n",
    "        predictions.append((go_terms, prob))  # Store GO terms and their probabilities\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Ensure X_test_tensor is on the same device as the models\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "\n",
    "# Get predictions from each model\n",
    "predictions_cc = predict_with_threshold(model_cc, X_test_tensor, cc_go_mapping, threshold=0.25, top_k=30)\n",
    "predictions_bp = predict_with_threshold(model_bp, X_test_tensor, bp_go_mapping, threshold=0.25, top_k=30)\n",
    "predictions_mf = predict_with_threshold(model_mf, X_test_tensor, mf_go_mapping, threshold=0.25, top_k=30)\n",
    "\n",
    "# Merge predictions into a dictionary\n",
    "final_predictions = {}\n",
    "for i, protein_id in enumerate(protein_ids):  # Ensure protein_ids matches test set order\n",
    "    all_terms = {}\n",
    "    \n",
    "    # Create a list of tuples for each branch along with its corresponding MLB\n",
    "    branch_predictions = [\n",
    "        (predictions_cc[i], mlb_cc),\n",
    "        (predictions_bp[i], mlb_bp),\n",
    "        (predictions_mf[i], mlb_mf)\n",
    "    ]\n",
    "    \n",
    "    for (go_terms, probs), mlb in branch_predictions:\n",
    "        for term in go_terms:\n",
    "            idx = np.where(mlb.classes_ == term)[0]\n",
    "            term_prob = probs[idx][0] if len(idx) > 0 else 0\n",
    "            \n",
    "            if term in all_terms:\n",
    "                all_terms[term] = max(all_terms[term], term_prob)  # Keep max probability\n",
    "            else:\n",
    "                all_terms[term] = term_prob\n",
    "    \n",
    "    # Sort by highest probabilities and keep top 1500 GO terms per protein\n",
    "    sorted_terms = sorted(all_terms.items(), key=lambda x: x[1], reverse=True)[:1500]\n",
    "    \n",
    "    final_predictions[protein_id] = sorted_terms\n",
    "\n",
    "# Save the predictions in submission format\n",
    "with open(\"submission.txt\", \"w\") as f:\n",
    "    for protein, terms in final_predictions.items():\n",
    "        for term, score in terms:\n",
    "            # If score is a numpy array, get the scalar value using .item()\n",
    "            if isinstance(score, np.ndarray):\n",
    "                formatted_score = round(score.item(), 3)\n",
    "            else:\n",
    "                # If score is already a scalar (int or float), directly round it\n",
    "                formatted_score = round(score, 3)\n",
    "\n",
    "            formatted_score = max(formatted_score, 0.001)  # Ensure score > 0\n",
    "            f.write(f\"{protein} {term} {formatted_score:.3f}\\n\")\n",
    "print(\"Submission file saved as submission.txt\")\n",
    "\n",
    "# Save the predictions in TSV format\n",
    "with open(\"submission.tsv\", \"w\") as f:\n",
    "    for protein, terms in final_predictions.items():\n",
    "        for term, score in terms:\n",
    "            # If score is a numpy array, get the scalar value using .item()\n",
    "            if isinstance(score, np.ndarray):\n",
    "                formatted_score = round(score.item(), 3)\n",
    "            else:\n",
    "                # If score is already a scalar (int or float), directly round it\n",
    "                formatted_score = round(score, 3)\n",
    "\n",
    "            formatted_score = max(formatted_score, 0.001)  # Ensure score > 0\n",
    "            # Write the protein, GO term, and probability as a tab-separated line\n",
    "            f.write(f\"{protein}\\t{term}\\t{formatted_score:.3f}\\n\")\n",
    "\n",
    "print(\"Submission file saved as submission.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
